{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88b05d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2464e36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42790, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>character</th>\n",
       "      <th>emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171_0001_A_1</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171_0001_A_2</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>c1</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171_0001_A_3</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171_0001_A_4</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>c1</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1171_0001_A_5</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            content character  \\\n",
       "0  1171_0001_A_1          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。        o2   \n",
       "1  1171_0001_A_2          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。        c1   \n",
       "2  1171_0001_A_3                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。        o2   \n",
       "3  1171_0001_A_4                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。        c1   \n",
       "4  1171_0001_A_5  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...        o2   \n",
       "\n",
       "      emotions  \n",
       "0  0,0,0,0,0,0  \n",
       "1  0,0,0,0,0,0  \n",
       "2  0,0,0,0,0,0  \n",
       "3  0,0,0,0,0,0  \n",
       "4  0,0,0,0,0,0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载训练集\n",
    "train = pd.read_csv('data/train_dataset_v2.tsv', sep='\\t', error_bad_lines=False, warn_bad_lines=False)\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9268b73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21376, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34170_0002_A_12</td>\n",
       "      <td>穿着背心的b1醒来，看看手机，三点了。</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34170_0002_A_14</td>\n",
       "      <td>b1走出卧室。</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34170_0003_A_16</td>\n",
       "      <td>b1拿着手机，点开计时功能。</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34170_0003_A_17</td>\n",
       "      <td>b1站在淋浴头下面，水从b1的头和脸上冲刷而过。</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34170_0003_A_18</td>\n",
       "      <td>b1摈着呼吸。</td>\n",
       "      <td>b1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                   content character\n",
       "0  34170_0002_A_12       穿着背心的b1醒来，看看手机，三点了。        b1\n",
       "1  34170_0002_A_14                   b1走出卧室。        b1\n",
       "2  34170_0003_A_16            b1拿着手机，点开计时功能。        b1\n",
       "3  34170_0003_A_17  b1站在淋浴头下面，水从b1的头和脸上冲刷而过。        b1\n",
       "4  34170_0003_A_18                   b1摈着呼吸。        b1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载测试集\n",
    "test = pd.read_csv('data/test_dataset.tsv', sep='\\t')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d74c2aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21376, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34170_0002_A_12</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34170_0002_A_14</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34170_0003_A_16</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34170_0003_A_17</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34170_0003_A_18</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id      emotion\n",
       "0  34170_0002_A_12  0,0,0,0,0,0\n",
       "1  34170_0002_A_14  0,0,0,0,0,0\n",
       "2  34170_0003_A_16  0,0,0,0,0,0\n",
       "3  34170_0003_A_17  0,0,0,0,0,0\n",
       "4  34170_0003_A_18  0,0,0,0,0,0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('data/submit_example.tsv', sep='\\t')\n",
    "print(submit.shape)\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6175d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36782, 4)\n"
     ]
    }
   ],
   "source": [
    "train = train[train['emotions'].notna()]\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d407b3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "无上文\n"
     ]
    }
   ],
   "source": [
    "def get_context(df, cur_id):\n",
    "    pos = cur_id.split('_')[-1]\n",
    "    # print(pos)\n",
    "    pos_str = str(int(pos) - 1)\n",
    "\n",
    "    location = train['id'][0][:-2] + '_' + pos_str\n",
    "    #print(location)\n",
    "    ret = train.loc[train['id'] == location]['content'].values.tolist()\n",
    "    if len(ret) == 1:\n",
    "        return ret[0]\n",
    "    else:\n",
    "        return \"无上文\"\n",
    "print(get_context(train, '1171_0001_A_1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d928a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['character'].fillna('无角色', inplace=True)\n",
    "test['character'].fillna('无角色', inplace=True)\n",
    "\n",
    "train['text'] = train['content'].astype(str) + ' 角色: ' + train['character'].astype(str)\n",
    "test['text'] = test['content'].astype(str) + ' 角色: ' + test['character'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a521f611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>character</th>\n",
       "      <th>emotions</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1171_0001_A_1</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1171_0001_A_2</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。</td>\n",
       "      <td>c1</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1171_0001_A_3</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: o2 上文: 天空下着暴雨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1171_0001_A_4</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。</td>\n",
       "      <td>c1</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: c1 上文: o2一手拿着...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1171_0001_A_5</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>o2</td>\n",
       "      <td>0,0,0,0,0,0</td>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                            content character  \\\n",
       "0  1171_0001_A_1          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。        o2   \n",
       "1  1171_0001_A_2          天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。        c1   \n",
       "2  1171_0001_A_3                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。        o2   \n",
       "3  1171_0001_A_4                       o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。        c1   \n",
       "4  1171_0001_A_5  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...        o2   \n",
       "\n",
       "      emotions                                               text  \n",
       "0  0,0,0,0,0,0  天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...  \n",
       "1  0,0,0,0,0,0  天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...  \n",
       "2  0,0,0,0,0,0  o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: o2 上文: 天空下着暴雨...  \n",
       "3  0,0,0,0,0,0  o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: c1 上文: o2一手拿着...  \n",
       "4  0,0,0,0,0,0  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add train context info\n",
    "for i in range(len(train['text'])):\n",
    "    try:\n",
    "        lcw = get_context(train, train['id'][i])\n",
    "    except:\n",
    "        continue\n",
    "    train['text'][i] += ' 上文: ' + lcw\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac83755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>character</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34170_0002_A_12</td>\n",
       "      <td>穿着背心的b1醒来，看看手机，三点了。</td>\n",
       "      <td>b1</td>\n",
       "      <td>穿着背心的b1醒来，看看手机，三点了。 角色: b1 上文: o2笑了笑：军礼不是这么敬的。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34170_0002_A_14</td>\n",
       "      <td>b1走出卧室。</td>\n",
       "      <td>b1</td>\n",
       "      <td>b1走出卧室。 角色: b1 上文: o2示范了一个动作，c1照做。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34170_0003_A_16</td>\n",
       "      <td>b1拿着手机，点开计时功能。</td>\n",
       "      <td>b1</td>\n",
       "      <td>b1拿着手机，点开计时功能。 角色: b1 上文: c1照做。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34170_0003_A_17</td>\n",
       "      <td>b1站在淋浴头下面，水从b1的头和脸上冲刷而过。</td>\n",
       "      <td>b1</td>\n",
       "      <td>b1站在淋浴头下面，水从b1的头和脸上冲刷而过。 角色: b1 上文: b1画外音：我叫b1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34170_0003_A_18</td>\n",
       "      <td>b1摈着呼吸。</td>\n",
       "      <td>b1</td>\n",
       "      <td>b1摈着呼吸。 角色: b1 上文: 无上文</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id                   content character  \\\n",
       "0  34170_0002_A_12       穿着背心的b1醒来，看看手机，三点了。        b1   \n",
       "1  34170_0002_A_14                   b1走出卧室。        b1   \n",
       "2  34170_0003_A_16            b1拿着手机，点开计时功能。        b1   \n",
       "3  34170_0003_A_17  b1站在淋浴头下面，水从b1的头和脸上冲刷而过。        b1   \n",
       "4  34170_0003_A_18                   b1摈着呼吸。        b1   \n",
       "\n",
       "                                                text  \n",
       "0  穿着背心的b1醒来，看看手机，三点了。 角色: b1 上文: o2笑了笑：军礼不是这么敬的。...  \n",
       "1                 b1走出卧室。 角色: b1 上文: o2示范了一个动作，c1照做。  \n",
       "2                    b1拿着手机，点开计时功能。 角色: b1 上文: c1照做。  \n",
       "3  b1站在淋浴头下面，水从b1的头和脸上冲刷而过。 角色: b1 上文: b1画外音：我叫b1...  \n",
       "4                             b1摈着呼吸。 角色: b1 上文: 无上文  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add test context info\n",
    "for i in range(len(test['id'])):\n",
    "    try:\n",
    "        lcw = get_context(test, test['id'][i])\n",
    "    except:\n",
    "        continue\n",
    "    test['text'][i] += ' 上文: ' + lcw\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af26da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['labels'] = train['emotions'].apply(lambda x: [int(i) for i in x.split(',')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74d18cf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: o2 上文: 天空下着暴雨...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: c1 上文: o2一手拿着...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text              labels\n",
       "0  天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...  [0, 0, 0, 0, 0, 0]\n",
       "1  天空下着暴雨，o2正在给c1穿雨衣，他自己却只穿着单薄的军装，完全暴露在大雨之中。 角色: ...  [0, 0, 0, 0, 0, 0]\n",
       "2  o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: o2 上文: 天空下着暴雨...  [0, 0, 0, 0, 0, 0]\n",
       "3  o2一手拿着一个行李，一路小跑着把c1带到了文工团门口。 角色: c1 上文: o2一手拿着...  [0, 0, 0, 0, 0, 0]\n",
       "4  o2停下来接过c1手里的行李：你妈妈交待我了，等领了军装一定要照张相寄回去，让街坊邻居都知道...  [0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train[['text', 'labels']].copy()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfc966ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33100 3682\n"
     ]
    }
   ],
   "source": [
    "#split train : dev = 9 : 1\n",
    "train_data_raw = train_data.sample(frac=1.0, random_state=42)\n",
    "train_data = train_data_raw[:33100]\n",
    "dev_data = train_data_raw[33100:]\n",
    "print(len(train_data), len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed940642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33100 3682\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(dev_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7a440c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers_clf.classification import (\n",
    "    MultiLabelClassificationModel as MultiLabelClassificationModelClf,\n",
    "    MultiLabelClassificationArgs\n",
    ")\n",
    "from simpletransformers_reg.classification import (\n",
    "    MultiLabelClassificationModel as MultiLabelClassificationModelReg,\n",
    "    MultiLabelClassificationArgs as MultiLabelClassificationArgsReg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5f295eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = MultiLabelClassificationArgs()\n",
    "model_args.max_seq_length = 128\n",
    "model_args.num_train_epochs = 3\n",
    "model_args.learning_rate = 3e-5\n",
    "model_args.do_lower_case = True\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.no_save = True\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.save_steps = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d2bdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForMultiLabelSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aabb26b494294714b8c2d2ac356e7e05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c4ac64435a046108980ddf9f0763ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b510d524d34f70908d0724165d99e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/4138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#model = MultiLabelClassificationModel('bert', 'hfl/chinese-bert-wwm-ext', num_labels=6)\n",
    "model = MultiLabelClassificationModelClf('bert', 'hfl/chinese-roberta-wwm-ext', num_labels=6, args=model_args)\n",
    "model.train_model(train_data)\n",
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da8b943a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2108201f854decb8046523e8c06589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5dde70f7d3c4e9cbc442ea14ad79c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分：0.7313271537885129\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs = model.predict([text for text in dev_data['text'].values])\n",
    "# raw_outputs[raw_outputs<=0.01] = 0.0\n",
    "# raw_outputs[raw_outputs >= 3.01] = 3.0\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "result = raw_outputs.tolist()\n",
    "test_y = dev_data['labels'].values.tolist()\n",
    "rmse = np.sqrt(mean_squared_error(result, test_y))\n",
    "score = 1.0 / (1+rmse)\n",
    "print(f\"得分：{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "664491c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(model, f'roberta_best_{score}_clf.pt')\n",
    "torch.save(model2, f'roberta_best_{score2}_reg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e8c12de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at hfl/chinese-roberta-wwm-ext were not used when initializing BertForMultiLabelSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at hfl/chinese-roberta-wwm-ext and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8d4b5e66364b3a8651f44fdb8ea05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33104 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6a77adfc414d43b8041f163c83df2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd01c25c6fef43139c17dc8a5d671d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 3:   0%|          | 0/4138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ed8499258240758d87e561d52ccb10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/4138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21c04d5f2104f0783a25460c30de864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/4138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(12414, 0.17814469151005682)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args2 = MultiLabelClassificationArgsReg()\n",
    "model_args2.max_seq_length = 128\n",
    "model_args2.num_train_epochs = 3\n",
    "model_args2.learning_rate = 3e-5\n",
    "model_args2.do_lower_case = True\n",
    "model_args2.overwrite_output_dir = True\n",
    "model_args2.no_save = True\n",
    "model_args2.save_model_every_epoch = False\n",
    "model_args2.save_steps = -1\n",
    "#model = MultiLabelClassificationModel('bert', 'hfl/chinese-bert-wwm-ext', num_labels=6)\n",
    "model2 = MultiLabelClassificationModelReg('bert', 'hfl/chinese-roberta-wwm-ext', num_labels=6, args=model_args2)\n",
    "model2.train_model(train_data)\n",
    "# eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1233c570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fffc2e465344cd844b42485b03e7db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3310 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de382adb455c4830985324fd3c30f8f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/414 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分：0.7661568740532065\n"
     ]
    }
   ],
   "source": [
    "predictions, raw_outputs2 = model2.predict([text for text in dev_data['text'].values])\n",
    "raw_outputs[raw_outputs<=0.001] = 0.0\n",
    "raw_outputs[raw_outputs >= 3.001] = 3.0\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "result2 = raw_outputs2.tolist()\n",
    "test_y = dev_data['labels'].values.tolist()\n",
    "rmse2 = np.sqrt(mean_squared_error(result2, test_y))\n",
    "score2 = 1.0 / (1+rmse2)\n",
    "print(f\"得分：{score2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "802f4620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "得分：0.7624120964566801\n"
     ]
    }
   ],
   "source": [
    "result3 = result2.copy()\n",
    "for i in range(len(result3)):\n",
    "    for j in range(len(result3[i])):\n",
    "        result3[i][j] = result[i][j] * result2[i][j]\n",
    "rmse3 = np.sqrt(mean_squared_error(result3, test_y))\n",
    "score3 = 1.0 / (1+rmse3)\n",
    "print(f\"得分：{score3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6de9ccf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defb514df25b421ea98bc841daf343de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c3dc96417041498d1df1d3de346c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8f80c351f64988a232f2a92bd8656b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21376 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9a9113302f46ac8dc7b607e6f8e4b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2672 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (3310) does not match length of index (21376)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_108349/305950190.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mto_submit3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mprob_submit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_submit\u001b[0m \u001b[0;31m#prob_submit['emotion'].apply(lambda x: ','.join([str(i) for i in x]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mprob_submit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprob_submit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'0927_s7313_roberta_clf_structured.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (3310) does not match length of index (21376)"
     ]
    }
   ],
   "source": [
    "# test\n",
    "_, raw_outputs1 = model.predict([text for text in test['text'].values])\n",
    "_, raw_outputs2 = model2.predict([text for text in test['text'].values])\n",
    "\n",
    "prob_submit = submit.copy()\n",
    "to_submit = []\n",
    "to_submit2 = []\n",
    "to_submit3 = []\n",
    "for i in range(len(raw_outputs)):\n",
    "    lst = raw_outputs1[i].tolist()\n",
    "    to_submit.append(','.join([str(i) for i in lst]))\n",
    "    lst2 = raw_outputs2[i].tolist()\n",
    "    to_submit2.append(','.join([str(i) for i in lst2]))\n",
    "    lst3 = len(lst) * [0]\n",
    "    for j in range(len(lst)):\n",
    "        lst3[j] = lst[j] * lst2[j]\n",
    "    to_submit3.append(','.join([str(i) for i in lst3]))\n",
    "    # break\n",
    "prob_submit['emotion'] = to_submit #prob_submit['emotion'].apply(lambda x: ','.join([str(i) for i in x]))\n",
    "prob_submit.head()\n",
    "prob_submit.to_csv(f'0927_s7313_roberta_clf_structured.tsv', sep='\\t', index=False)\n",
    "prob_submit['emotion'] = to_submit2 #prob_submit['emotion'].apply(lambda x: ','.join([str(i) for i in x]))\n",
    "prob_submit.head()\n",
    "prob_submit.to_csv(f'0927_s7661_roberta_reg_structured.tsv', sep='\\t', index=False)\n",
    "prob_submit['emotion'] = to_submit3\n",
    "prob_submit.head()\n",
    "prob_submit.to_csv(f'0927_s7624_roberta_mix_structured.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08562ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.values[3]\n",
    "# # sub probs\n",
    "# prob_submit = sub.copy()\n",
    "# to_submit = []\n",
    "# # prob_submit['emotion'] = raw_outputs\n",
    "# for i in range(len(raw_outputs)):\n",
    "#     lst = raw_outputs[i].tolist()\n",
    "#     to_submit.append(','.join([str(i * 3) for i in lst]))\n",
    "#     # break\n",
    "# prob_submit['emotion'] = to_submit #prob_submit['emotion'].apply(lambda x: ','.join([str(i) for i in x]))\n",
    "# prob_submit.head()\n",
    "# prob_submit.to_csv('4epoch_2e05_probs_emplified_roberta.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MultiLabelClassificationModel('bert', 'outputs', num_labels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d741e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "# import pandas as pd\n",
    "# import logging\n",
    "\n",
    "\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "# transformers_logger = logging.getLogger(\"transformers\")\n",
    "# transformers_logger.setLevel(logging.WARNING)\n",
    "# train_data_0 = []\n",
    "# train_data_1 = []\n",
    "# train_data_2 = []\n",
    "# train_data_3 = []\n",
    "# train_data_4 = []\n",
    "# train_data_5 = []\n",
    "\n",
    "# for i in range(len(train_data['text'])):\n",
    "#     try:\n",
    "#         ## train data\n",
    "#         train_data_0.append([train_data['text'][i], train_data['labels'][i][0]])\n",
    "#         train_data_1.append([train_data['text'][i], train_data['labels'][i][1]])\n",
    "#         train_data_2.append([train_data['text'][i], train_data['labels'][i][2]])\n",
    "#         train_data_3.append([train_data['text'][i], train_data['labels'][i][3]])\n",
    "#         train_data_4.append([train_data['text'][i], train_data['labels'][i][4]])\n",
    "#         train_data_5.append([train_data['text'][i], train_data['labels'][i][5]])\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "# dev_data_0 = []\n",
    "# dev_data_1 = []\n",
    "# dev_data_2 = []\n",
    "# dev_data_3 = []\n",
    "# dev_data_4 = []\n",
    "# dev_data_5 = []\n",
    "\n",
    "# for i in range(len(dev_data['text'])):\n",
    "#     try:\n",
    "#         ## train data\n",
    "#         dev_data_0.append([dev_data['text'][i], dev_data['labels'][i][0]])\n",
    "#         dev_data_1.append([dev_data['text'][i], dev_data['labels'][i][1]])\n",
    "#         dev_data_2.append([dev_data['text'][i], dev_data['labels'][i][2]])\n",
    "#         dev_data_3.append([dev_data['text'][i], dev_data['labels'][i][3]])\n",
    "#         dev_data_4.append([dev_data['text'][i], dev_data['labels'][i][4]])\n",
    "#         dev_data_5.append([dev_data['text'][i], dev_data['labels'][i][5]])\n",
    "#     except:\n",
    "#         continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d53dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df_0 = pd.DataFrame(train_data_0)\n",
    "# train_df_0.columns = [\"text\", \"labels\"]\n",
    "# train_df_1 = pd.DataFrame(train_data_1)\n",
    "# train_df_1.columns = [\"text\", \"labels\"]\n",
    "# train_df_2 = pd.DataFrame(train_data_2)\n",
    "# train_df_2.columns = [\"text\", \"labels\"]\n",
    "# train_df_3 = pd.DataFrame(train_data_3)\n",
    "# train_df_3.columns = [\"text\", \"labels\"]\n",
    "# train_df_4 = pd.DataFrame(train_data_4)\n",
    "# train_df_4.columns = [\"text\", \"labels\"]\n",
    "# train_df_5 = pd.DataFrame(train_data_5)\n",
    "# train_df_5.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a228b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_df_0 = pd.DataFrame(dev_data_0)\n",
    "# dev_df_0.columns = [\"text\", \"labels\"]\n",
    "# dev_df_1 = pd.DataFrame(dev_data_1)\n",
    "# dev_df_1.columns = [\"text\", \"labels\"]\n",
    "# dev_df_2 = pd.DataFrame(dev_data_2)\n",
    "# dev_df_2.columns = [\"text\", \"labels\"]\n",
    "# dev_df_3 = pd.DataFrame(dev_data_3)\n",
    "# dev_df_3.columns = [\"text\", \"labels\"]\n",
    "# dev_df_4 = pd.DataFrame(dev_data_4)\n",
    "# dev_df_4.columns = [\"text\", \"labels\"]\n",
    "# dev_df_5 = pd.DataFrame(dev_data_5)\n",
    "# dev_df_5.columns = [\"text\", \"labels\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de5ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_0 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_0')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_0 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_0\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_0.train_model(train_df_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cec1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_1 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_1')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_1 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_1\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_1.train_model(train_df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5376e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_2 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_2')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_2 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_2\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_2.train_model(train_df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18d0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_3 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_3')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_3 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_3\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_3.train_model(train_df_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e8eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_4 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_4')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_4 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_4\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_4.train_model(train_df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8afba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional model configuration\n",
    "# model_args_5 = ClassificationArgs(learning_rate = 2e-5, num_train_epochs=4, output_dir='outputs_5')\n",
    "\n",
    "# # Create a ClassificationModel\n",
    "# model_5 = ClassificationModel(\n",
    "#     'bert',\n",
    "#     'hfl/chinese-roberta-wwm-ext',\n",
    "#     num_labels=4,\n",
    "#     args=model_args_5\n",
    "# ) \n",
    "# # Train the model\n",
    "# model_5.train_model(train_df_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ed59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_0 = ClassificationModel('bert', 'outputs_0', num_labels=4)\n",
    "# model_1 = ClassificationModel('bert', 'outputs_1', num_labels=4)\n",
    "# model_2 = ClassificationModel('bert', 'outputs_2', num_labels=4)\n",
    "# model_3 = ClassificationModel('bert', 'outputs_3', num_labels=4)\n",
    "# model_4 = ClassificationModel('bert', 'outputs_4', num_labels=4)\n",
    "# model_5 = ClassificationModel('bert', 'outputs_5', num_labels=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad557336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multi-classification\n",
    "# _, raw_output_0 = model_0.predict([text for text in dev_data['text'].values])\n",
    "# _, raw_output_1 = model_1.predict([text for text in dev_data['text'].values])\n",
    "# _, raw_output_2 = model_2.predict([text for text in dev_data['text'].values])\n",
    "# _, raw_output_3 = model_3.predict([text for text in dev_data['text'].values])\n",
    "# _, raw_output_4 = model_4.predict([text for text in dev_data['text'].values])\n",
    "# _, raw_output_5 = model_5.predict([text for text in dev_data['text'].values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ae7177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import math\n",
    "\n",
    "# # custom function\n",
    "# def sigmoid(x):\n",
    "#     return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# # define vectorized sigmoid\n",
    "# sigmoid_v = np.vectorize(sigmoid)\n",
    "\n",
    "# raw_output_0 = sigmoid_v(raw_output_0).tolist()\n",
    "# raw_output_1 = sigmoid_v(raw_output_1).tolist()\n",
    "# raw_output_2 = sigmoid_v(raw_output_2).tolist()\n",
    "# raw_output_3 = sigmoid_v(raw_output_3).tolist()\n",
    "# raw_output_4 = sigmoid_v(raw_output_4).tolist()\n",
    "# raw_output_5 = sigmoid_v(raw_output_5).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a74780",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # eval on joint model\n",
    "# predictions, raw_outputs = model.predict([text for text in dev_data['text'].values])\n",
    "# raw_outputs[raw_outputs<=0.01] = 0\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# result = raw_outputs.tolist()\n",
    "# for i in range(len(result)):\n",
    "#     for j in range(6):\n",
    "#         if result[i][j] > 0.95:\n",
    "#             if j == 0:\n",
    "#                 max_prob = max(raw_output_0[i])\n",
    "#                 max_indx = raw_output_0[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 1:\n",
    "#                 max_prob = max(raw_output_1[i])\n",
    "#                 max_indx = raw_output_1[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 2:\n",
    "#                 max_prob = max(raw_output_2[i])\n",
    "#                 max_indx = raw_output_2[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 3:\n",
    "#                 max_prob = max(raw_output_3[i])\n",
    "#                 max_indx = raw_output_3[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 4:\n",
    "#                 max_prob = max(raw_output_4[i])\n",
    "#                 max_indx = raw_output_4[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 5:\n",
    "#                 max_prob = max(raw_output_5[i])\n",
    "#                 max_indx = raw_output_5[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "# test_y = dev_data['labels'].values.tolist()\n",
    "# rmse = np.sqrt(mean_squared_error(result, test_y))\n",
    "# score = 1.0 / (1+rmse)\n",
    "# print(f\"得分：{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd449631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # multi-classification\n",
    "# _, raw_output_0 = model_0.predict([text for text in test['text'].values])\n",
    "# _, raw_output_1 = model_1.predict([text for text in test['text'].values])\n",
    "# _, raw_output_2 = model_2.predict([text for text in test['text'].values])\n",
    "# _, raw_output_3 = model_3.predict([text for text in test['text'].values])\n",
    "# _, raw_output_4 = model_4.predict([text for text in test['text'].values])\n",
    "# _, raw_output_5 = model_5.predict([text for text in test['text'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc44e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_output_0 = sigmoid_v(raw_output_0).tolist()\n",
    "# raw_output_1 = sigmoid_v(raw_output_1).tolist()\n",
    "# raw_output_2 = sigmoid_v(raw_output_2).tolist()\n",
    "# raw_output_3 = sigmoid_v(raw_output_3).tolist()\n",
    "# raw_output_4 = sigmoid_v(raw_output_4).tolist()\n",
    "# raw_output_5 = sigmoid_v(raw_output_5).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c0d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # test\n",
    "# predictions, raw_outputs = model.predict([text for text in test['text'].values])\n",
    "# raw_outputs[raw_outputs<=0.01] = 0\n",
    "# # sub probs\n",
    "# prob_submit = submit.copy()\n",
    "# to_submit = []\n",
    "# result = raw_outputs.tolist()\n",
    "# for i in range(len(result)):\n",
    "#     for j in range(6):\n",
    "#         if result[i][j] > 0.95:\n",
    "#             if j == 0:\n",
    "#                 max_prob = max(raw_output_0[i])\n",
    "#                 max_indx = raw_output_0[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 1:\n",
    "#                 max_prob = max(raw_output_1[i])\n",
    "#                 max_indx = raw_output_1[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 2:\n",
    "#                 max_prob = max(raw_output_2[i])\n",
    "#                 max_indx = raw_output_2[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 3:\n",
    "#                 max_prob = max(raw_output_3[i])\n",
    "#                 max_indx = raw_output_3[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 4:\n",
    "#                 max_prob = max(raw_output_4[i])\n",
    "#                 max_indx = raw_output_4[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "#             elif j == 5:\n",
    "#                 max_prob = max(raw_output_5[i])\n",
    "#                 max_indx = raw_output_5[i].index(max_prob)\n",
    "#                 if max_indx == 0:\n",
    "#                     continue\n",
    "#                 result[i][j] = max_prob * max_indx\n",
    "# # prob_submit['emotion'] = raw_outputs\n",
    "# for i in range(len(result)):\n",
    "#     lst = result[i]\n",
    "#     to_submit.append(','.join([str(i) for i in lst]))\n",
    "#     # break\n",
    "# prob_submit['emotion'] = to_submit #prob_submit['emotion'].apply(lambda x: ','.join([str(i) for i in x]))\n",
    "# prob_submit.head()\n",
    "# prob_submit.to_csv('0922_s6905_bert_fusion.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b34338",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0f7ec9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ba46a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
